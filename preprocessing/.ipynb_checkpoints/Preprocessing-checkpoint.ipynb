{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import glob\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "import shutil\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skull_strip(sub, path):\n",
    "    print(\">>>>---> starting bet on \", sub )\n",
    "    try:\n",
    "        for nifti in glob.glob(os.path.join(path, '%s/func/*desc-preproc_bold.nii.gz'%sub)):\n",
    "            # make our variables\n",
    "            filename = nifti.split(\"/\")[-1].split(\".\")[0]\n",
    "            bet_name=filename+'_brain'\n",
    "            bet_output = os.path.join(path,\"%s/func\"%sub, bet_name)\n",
    "            print(\"SKULL STRIP, NEW FILE TO BE MADE: \", bet_name)\n",
    "            if os.path.exists(bet_output + '.nii'):\n",
    "                print(bet_output + ' exists, skipping \\n')\n",
    "            else:\n",
    "                print(\"Running bet on \", nifti)\n",
    "                bet_cmd=(\"bet %s %s -F -m -f %s\"%(nifti, bet_output, \"0.6\"))\n",
    "                print(\">>>-----> BET COMMAND:\", bet_cmd)\n",
    "                os.system(bet_cmd)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "global deriv_path\n",
    "deriv_path= \"/projects/niblab/bids_projects/Experiments/Bevel/testing_lin/derivatives\"\n",
    "subjects = sorted(glob.glob(os.path.join(deriv_path, \"sub-0*\")))\n",
    "\n",
    "    \n",
    "def main(subjects):\n",
    "    for path in subjects:\n",
    "        sub_id = path.split(\"/\")[-1]\n",
    "        skull_strip(sub_id,deriv_path)\n",
    "    \n",
    "half = int(len(subjects)/2)\n",
    "B,C = subjects[:half], subjects[half:]\n",
    "pool = Pool(processes=2)\n",
    "pool.map(main, [B,C])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_check(sub, outfile, out_bad_bold_list, derivatives_dir):\n",
    "    func_path = os.path.join(derivatives_dir, sub, \"func\")\n",
    "    print(\">>>>---> Starting motion correction on \", sub)\n",
    "    motion_assessment_path=os.path.join(derivatives_dir, sub, 'func','motion_assessment')\n",
    "    if not os.path.exists(motion_assessment_path):\n",
    "        os.makedirs(motion_assessment_path)\n",
    "    try:\n",
    "# iterate over nifti file\n",
    "        for nifti in glob.glob(os.path.join(func_path, '*_brain.nii*')):\n",
    "            filename=nifti.split('.')[0]\n",
    "            file = filename.split(\"/\")[-1]\n",
    "            outlier_path = \"%s/%s_outlier_output.txt\"%(motion_assessment_path, file)\n",
    "            plot_path = \"%s/%s_fd_plot\"%(motion_assessment_path, file)\n",
    "            confound_path = \"%s/%s_confound.txt\"%(motion_assessment_path, file)\n",
    "            #need to get identifier for tasks and runs --rn for bevel, need to specify for versatility \n",
    "            # set comparison param\n",
    "            nvols_cmd=\"fslnvols \" + nifti\n",
    "            volume = subprocess.check_output(nvols_cmd, shell=True, encoding=\"utf-8\")\n",
    "            volume = volume.strip()\n",
    "            comparator = int(volume) *.25\n",
    "            ## RUN 'fsl_motion_outliers' TO RETRIEVE MOTION CORRECTION ANALYSIS\n",
    "            outlier_cmd = \"fsl_motion_outliers -i %s  -o %s --fd --thresh=%s -p %s -v > %s\"%(filename, confound_path, \"0.9\", plot_path, outlier_path)\n",
    "            print(\">>-->  RUNNING FSL MOTION OUTLIERS \")\n",
    "            print(\"COMMAND NVOLS: \", nvols_cmd)\n",
    "            print(\"OUTLIER CMD: \", outlier_cmd)\n",
    "            os.system(outlier_cmd)\n",
    "        ## EXAMINE OUTLIER FILE AND GRAB RELEVANT DATA \n",
    "            with open(outlier_path, 'r') as f:\n",
    "                lines=f.readlines()\n",
    "                statsA = lines[1].strip(\"\\n\") #maskmean\n",
    "                statsB = lines[3].strip(\"\\n\") #metric range\n",
    "                statsC = lines[4].strip(\"\\n\") #outliers found\n",
    "                if int(statsC.split(\" \")[1])  > 0:\n",
    "                    statsD = lines[6].strip(\"\\n\") #spikes found\n",
    "                else:\n",
    "                    statsD = \"\\n\"\n",
    "            f.close()\n",
    "        ## GRAB MOTION CORRECTION PLOT AND WRITE PLOT & INFO TO HTML\n",
    "            plotz=plot_path+\".png\"\n",
    "            FILEINFO=\"\"\"<p><font size=6> <b>{CURR_FILENAME} </b></font><br>\"\"\"\n",
    "            CURR_FILEINFO = FILEINFO.format(CURR_FILENAME=file)\n",
    "            outfile.write(CURR_FILEINFO)\n",
    "            INFO=\"\"\"<p><font size=6>{A} <br><b>{B}<b><br>{C}<br><b>{D}</b><br><br>\"\"\"\n",
    "            CURR_INFO= INFO.format(A=statsA, B=statsB, C=statsC, D=statsD)\n",
    "            outfile.write(CURR_INFO)\n",
    "            PLOT=\"\"\"<IMG SRC=\\\"{PLOTPATH}\\\" WIDTH=100%><br><br>\"\"\"\n",
    "            CURR_PLOT = PLOT.format(PLOTPATH=plotz)\n",
    "            outfile.write(CURR_PLOT)\n",
    "            print(\">>>>----> ADDING PLOT TO HTML\")\n",
    "                ## ADD FILE FOR GOOD SUBJECT \n",
    "        # --sometimes you have a great subject who didn't move\n",
    "            if os.path.isfile(confound_path)==False:\n",
    "                os.system(\"touch %s\"%confound_path)\n",
    "                \n",
    "        ## CHECK FOR BAD SUBJECTS: ABOVE OUR THRESHOLD\n",
    "        # how many columns are there = how many 'bad' points\n",
    "            check = subprocess.check_output(\"grep -o 1 %s | wc -l\"%(confound_path), shell=True)\n",
    "            num_scrub = [int(s) for s in check.split() if s.isdigit()]\n",
    "            print(\"NUM SCRUB: \", str(num_scrub[0]), \"\\n\")\n",
    "            if num_scrub[0] > comparator: #if the number in check is greater than num_scrub then we don't want it\n",
    "                with open(out_bad_bold_list, \"a\") as myfile: #making a file that lists all the bad ones\n",
    "                    myfile.write(\"%s/%s\\n\"%(derivatives_dir, file))\n",
    "                    print(\"wrote bad file\")\n",
    "                myfile.close()\n",
    "    except FileNotFoundError:   \n",
    "        print(\"FILE IS EMPTY, PASSING\")\n",
    "\n",
    "datestamp=datetime.datetime.now().strftime(\"%Y-%m-%d-%H_%M_%S\")\n",
    "\n",
    "outhtml = os.path.join(deriv_path,'bold_motion_QA_%s.html'%(datestamp))\n",
    "out_bad_bold_list = os.path.join(deriv_path,'%s_TEST.txt'%(datestamp))\n",
    "        \n",
    "    # OPEN HTML FILE IF CASE TRUE\n",
    "outfile = open(outhtml, 'a')\n",
    "TITLE=\"\"\"<p><font size=7> <b> Motion Correction Check</b></font><br>\"\"\"\n",
    "outfile.write(\"%s\"%TITLE)\n",
    "\n",
    "\n",
    "    \n",
    "for path in subjects:\n",
    "    sub_id = path.split(\"/\")[-1]\n",
    "    fd_check(sub_id, outfile,\n",
    "             out_bad_bold_list, deriv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_files(filename, moco_df, outputdir):\n",
    "    # iterate through the motion correction data frame by columns, writing individual columns to individual files\n",
    "    for col in moco_df.columns:\n",
    "        file= \"%s_%s.txt\"%(filename, col)\n",
    "        output_path=os.path.join(outputdir, file)\n",
    "        print(\"Writing to file, \", output_path)\n",
    "        moco_df[col].to_csv(output_path, header=False, index=False)\n",
    "\n",
    "\n",
    "def get_motion_parameters(sub):\n",
    "    errors = []\n",
    "    motion_assessment_path =os.path.join( deriv_path, sub, \"func/motion_assessment\" ) \n",
    "    moco_avail = len(glob.glob(os.path.join(motion_assessment_path, \"motion_parameters/*.txt\")))\n",
    "    #print(sub,moco_avail)\n",
    "    if moco_avail < 0:\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "        #print(\"--------------> GETTING MOCOS FOR SUBJECT: \", sub)\n",
    "            outputdir = os.path.join(motion_assessment_path, \"motion_parameters\")\n",
    "            if not os.path.exists(os.path.join(outputdir, 'motion_parameters')):\n",
    "                os.makedirs(os.path.join(outputdir, 'motion_parameters'))\n",
    "            confound_path = \"/projects/niblab/bids_projects/Experiments/Bevel/fmriprep2/fmriprep/%s/func/%s_task-*_desc-confounds_regressors.tsv\"%(sub, sub)\n",
    "            confounds = glob.glob(confound_path)\n",
    "            #print(confound_path)\n",
    "            for confound in confounds:\n",
    "                #print(confound)\n",
    "                df_s1 = pd.read_table(confound)\n",
    "                #print(df_s1)\n",
    "                moco= df_s1[['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z']]\n",
    "                moco.columns = [\"moco0\", \"moco1\", \"moco2\", \"moco3\", \"moco4\", \"moco5\"]\n",
    "                #print(\"DATAFRAME: \\n \", moco.head())\n",
    "                filename = confound.split(\"/\")[-1].split(\"_desc-confounds_regressors\")[0]\n",
    "                print(\"FILENAME: \", filename)\n",
    "                write_files(filename, moco, outputdir)\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "deriv_path= \"/projects/niblab/bids_projects/Experiments/Bevel/derivatives\"\n",
    "subjects = sorted(glob.glob(os.path.join(deriv_path, \"sub-*\")))\n",
    "\n",
    "    \n",
    "for path in subjects:\n",
    "    sub_id = path.split(\"/\")[-1]\n",
    "    get_motion_parameters(sub_id)\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
