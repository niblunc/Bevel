{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running One Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # interact with the filesystem\n",
    "from subprocess import Popen, PIPE, STDOUT  # enable calling commandline\n",
    "import matplotlib.pyplot as plt  # manipulate figures\n",
    "import seaborn as sns  # display results\n",
    "import pandas as pd   # manipulate tabular \n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=ResourceWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data\n",
    "\n",
    "Set the \"working directory\" path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/projects/niblab/bids_projects/Experiments/Bevel/testing_beta' #RENCI PATH\n",
    "#data_dir = '/Users/nikkibytes/Documents/niblunc/testing_beta' #LOCAL PATH\n",
    "print('Our working directory: {}'.format(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set our `*.tsv` events file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the original `*events.tsv` file and extract the columns we need to run the betaseries analysis.\n",
    "For this we simply take 4 specific columns and then fill them into the `sub-*_task_prob_run-*_events.tsv` originally generated as output from BIDS. \n",
    "\n",
    "Here you can see we load the original `*.tsv` file, rename column names from the original to the standarize name, \"outcome becomes \"trial_type\" and \"RT\" becomes \"response_time\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we need to format our `*.tsv` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_file = os.path.join(data_dir, 'sub-001/func/sub-001_task-prob_run-1_events.tsv')\n",
    "events_df = pd.read_csv(events_file, sep=\"\\t\", na_values=\"n/a\")\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename our original columns\n",
    "events_df.rename({\"outcome\": \"trial_type\"}, axis='columns', inplace=True)\n",
    "events_df.head()\n",
    "events_df.rename({\"RT\": \"response_time\"}, axis='columns', inplace=True)\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = events_df.dropna(axis=\"rows\")\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df= events_df[[\"onset\", \"duration\", 'trial_type', 'response_time']]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfile = os.path.join(data_dir, 'sub-001/func/sub-001_task-prob_run-1_events.tsv')\n",
    "new_df.to_csv(newfile, sep=\"\\t\", na_rep=\"n/a\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup atlas file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_txt = os.path.join(data_dir,\n",
    "                         \"derivatives\",\n",
    "                         \"data\",\n",
    "                         \"Schaefer2018_100Parcels_7Networks_order.txt\")\n",
    "atlas_df = pd.read_csv(atlas_txt, sep=\"\\t\", header=None)\n",
    "atlas_df.head()\n",
    "\n",
    "atlas_df.drop([2, 3, 4, 5], axis='columns', inplace=True)\n",
    "atlas_df.head()\n",
    "\n",
    "atlas_df.rename({0: 'index', 1: 'regions'}, axis='columns', inplace=True)\n",
    "atlas_df.head()\n",
    "\n",
    "atlas_df.replace(regex={'7Networks_(.*)': '\\\\1'}, inplace=True)\n",
    "atlas_df.head()\n",
    "\n",
    "atlas_tsv = atlas_txt.replace(\".txt\", \".tsv\")\n",
    "atlas_df.to_csv(atlas_tsv, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the nibs command and run\n",
    "Here we set our flags for betaseries, print to check it and then run  \n",
    "Note \n",
    "    * the `-c` flag is our confound flag, \"the confound column names that are to be included in nuisance regression. write the confounds you wish to include separated by a space\". <WhiteMatter, CSF, Cosine0, X, RotX, etc.....>\n",
    "\n",
    "    * `-sp` which is our space derivative, where we select a bold derivative in a specific space to be used, currenlty only space available is the `MNI152NLin2009cAsym`\n",
    "    * -`sm` is our smoothing kernel (optional)\n",
    "    * the other inputs are specific directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join(data_dir, \"derivatives/basic_output\")\n",
    "work_dir = os.path.join(out_dir, \"work_dir_test\")\n",
    "atlas_mni_file = os.path.join(data_dir,\n",
    "                              \"derivatives\",\n",
    "                              \"data\",\n",
    "                              \"Schaefer2018_100Parcels_7Networks_order_FSLMNI152_2mm.nii.gz\")\n",
    "print('Our output directory: {}'.format(out_dir))\n",
    "print('Our working output directory: {}'.format(work_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run parallel\n",
    "# \n",
    "cmd = \"\"\"\\\n",
    "nibs \\\n",
    "{bids_dir} \\\n",
    "fmriprep \\\n",
    "{out_dir} \\\n",
    "participant \\\n",
    "-sm 6 \\\n",
    "--run_label 4 \\\n",
    "-c WhiteMatter CSF \\\n",
    "-sp MNI152NLin2009cAsym \\\n",
    "-w {work_dir} \\\n",
    "-a {atlas_mni_file} \\\n",
    "-l {atlas_tsv} \\\n",
    "\"\"\".format(atlas_mni_file=atlas_mni_file,\n",
    "           atlas_tsv=atlas_tsv,\n",
    "           bids_dir=os.path.join(data_dir),\n",
    "           out_dir=out_dir,\n",
    "           work_dir=work_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Since we cannot run bash commands inside this tutorial\n",
    "# we are printing the actual bash command so you can see it\n",
    "# in the output\n",
    "print(\"The Example Command:\\n\", cmd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call nibs\n",
    "\n",
    "p = Popen(cmd, shell=True, stdout=PIPE, stderr=STDOUT)\n",
    "\n",
    "while True:\n",
    "    line = p.stdout.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat_path = os.path.join(out_dir, \"NiBetaSeries\", \"nibetaseries\", \"sub-001\", \"func\")\n",
    "trial_types = ['punish','reward']\n",
    "filename_template = \"sub-001_task-prob_run-1_bold_space-MNI152NLin2009cAsym_preproc_trialtype-{trial_type}_matrix.tsv\"\n",
    "pd_dict = {}\n",
    "\n",
    "for trial_type in trial_types:\n",
    "    file_path = os.path.join(corr_mat_path, filename_template.format(trial_type=trial_type))\n",
    "    print(file_path)\n",
    "    pd_dict[trial_type] = pd.read_csv(file_path, sep='\\t', na_values=\"n/a\", index_col=0)\n",
    "# display example matrix\n",
    "    print(pd_dict[trial_type].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=True, figsize=(10, 30),\n",
    "                         gridspec_kw={'wspace': 0.025, 'hspace': 0.075})\n",
    "\n",
    "cbar_ax = fig.add_axes([.91, .3, .03, .4])\n",
    "r = 0\n",
    "\n",
    "for trial_type, df in pd_dict.items():\n",
    "    g = sns.heatmap(df, ax=axes[r], center=0, square=True,\n",
    "                    cbar=True, cbar_ax=cbar_ax)\n",
    "    axes[r].set_title(trial_type)\n",
    "    # iterate over rows\n",
    "    r += 1\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(corr_mat_path, \"run-1_task_heatmap.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
